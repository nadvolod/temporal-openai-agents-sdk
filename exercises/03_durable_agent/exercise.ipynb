{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bd855c9",
   "metadata": {},
   "source": [
    "# Exercise 3: Durable Agent\n",
    "\n",
    "**Goal:** Combine OpenAI agents with Temporal workflows to create a durable AI agent with automatic retries and state persistence.\n",
    "\n",
    "**Timebox:** 15 minutes\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- How to wrap LLM calls in Temporal activities for durability\n",
    "- How to persist agent state across failures using workflows\n",
    "- How to correlate Temporal execution with OpenAI traces using trace IDs\n",
    "- How automatic retries work for AI operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4020a341",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Ensure the Temporal dev server is running before executing the exercise.\n",
    "\n",
    "```bash\n",
    "make temporal-up\n",
    "```\n",
    "\n",
    "Add your OpenAI credentials to `.env` if you have not already."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8837149",
   "metadata": {},
   "source": [
    "## Steps\n",
    "\n",
    "1. **Wrap LLM calls in an activity** â€“ Complete `call_agent_with_tools` below so LLM requests run through Temporal.\n",
    "2. **Create the workflow** â€“ Implement `DurableAgentWorkflow` to call the activity with a retry policy.\n",
    "3. **Add observability** â€“ Generate a `trace_id` and log key information for debugging.\n",
    "4. **Run the workflow** â€“ Use the helper cell to start a worker and execute the workflow.\n",
    "5. **Inspect history** â€“ Open http://localhost:8233 to observe execution state and retries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9ab7b9",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Install dependencies and import the Temporal + OpenAI helpers used in this exercise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07649b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --quiet temporalio openai rich\n",
    "\n",
    "import os\n",
    "import asyncio\n",
    "import uuid\n",
    "from datetime import timedelta\n",
    "from openai import OpenAI\n",
    "from rich.console import Console\n",
    "from temporalio import activity, workflow\n",
    "from temporalio.client import Client\n",
    "from temporalio.common import RetryPolicy\n",
    "from temporalio.worker import Worker\n",
    "\n",
    "console = Console()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e9b875",
   "metadata": {},
   "source": [
    "## Helper Tool Function\n",
    "\n",
    "Implement a simple weather lookup to support the agent tool call.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cda1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"Return mock weather data for a location.\"\"\"\n",
    "    # TODO: extend or modify the lookup table\n",
    "    weather_data = {\n",
    "        \"San Francisco\": \"sunny, 72Â°F\",\n",
    "        \"New York\": \"cloudy, 65Â°F\",\n",
    "        \"London\": \"rainy, 58Â°F\",\n",
    "        \"Tokyo\": \"clear, 70Â°F\",\n",
    "    }\n",
    "    weather = weather_data.get(location, \"partly cloudy, 68Â°F\")\n",
    "    return f\"The weather in {location} is {weather}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2933a3c",
   "metadata": {},
   "source": [
    "## Implement the Activity\n",
    "\n",
    "Wrap the LLM call in a Temporal activity so it can retry safely.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4047576",
   "metadata": {},
   "outputs": [],
   "source": [
    "@activity.defn\n",
    "async def call_agent_with_tools(query: str, trace_id: str) -> str:\n",
    "    \"\"\"Call the LLM with tool support and return the final message.\"\"\"\n",
    "    # TODO: log the incoming query and trace ID\n",
    "    # TODO: build the tools list that exposes the get_weather helper\n",
    "    # TODO: call the OpenAI client and handle any tool invocations\n",
    "    # TODO: return the agent's final response string\n",
    "    raise NotImplementedError(\"Implement call_agent_with_tools\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adc84a3",
   "metadata": {},
   "source": [
    "## Implement the Workflow\n",
    "\n",
    "Add retries and logging to orchestrate the activity invocation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13391d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@workflow.defn\n",
    "class DurableAgentWorkflow:\n",
    "    @workflow.run\n",
    "    async def run(self, query: str, trace_id: str) -> str:\n",
    "        # TODO: log the query and trace ID for observability\n",
    "        # TODO: execute the call_agent_with_tools activity with a RetryPolicy\n",
    "        # TODO: return the agent's response to the caller\n",
    "        raise NotImplementedError(\"Implement DurableAgentWorkflow.run\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e7f91f",
   "metadata": {},
   "source": [
    "## Expected Output\n",
    "\n",
    "```\n",
    "ðŸš€ Starting Durable Agent workflow...\n",
    "   Trace ID: 550e8400-e29b-41d4-a716-446655440000\n",
    "\n",
    "ðŸ¤– Agent Query: What's the weather in San Francisco?\n",
    "\n",
    "ðŸ”§ Activity: Calling tool get_weather(location=\"San Francisco\")\n",
    "âœ“ Tool result: The weather in San Francisco is sunny, 72Â°F\n",
    "\n",
    "ðŸ¤– Agent Response:\n",
    "The current weather in San Francisco is sunny with a temperature of 72Â°F.\n",
    "\n",
    "âœ… Workflow completed successfully\n",
    "\n",
    "View in Temporal UI: http://localhost:8233/namespaces/default/workflows/durable-agent-1\n",
    "Trace ID for correlation: 550e8400-e29b-41d4-a716-446655440000\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a80722d",
   "metadata": {},
   "source": [
    "## Implement the Workflow\n",
    "\n",
    "Create a workflow that calls your activity and applies a retry policy for durability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb57e720",
   "metadata": {},
   "outputs": [],
   "source": [
    "@workflow.defn\n",
    "class DurableAgentWorkflow:\n",
    "    @workflow.run\n",
    "    async def run(self, query: str, trace_id: str) -> str:\n",
    "        # TODO: log the workflow start and input\n",
    "        # TODO: call the activity with a retry policy\n",
    "        # TODO: return the agent response\n",
    "        raise NotImplementedError(\"Implement DurableAgentWorkflow.run\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d6232c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@activity.defn\n",
    "async def call_agent_with_tools(query: str, trace_id: str) -> str:\n",
    "    \"\"\"Call the LLM agent with tool support and retry logic.\"\"\"\n",
    "    # TODO: log the query and trace_id\n",
    "    # TODO: set up OpenAI client and tool schema\n",
    "    # TODO: make the initial API call and handle tool calls\n",
    "    # TODO: return the final agent response\n",
    "    raise NotImplementedError(\"Implement call_agent_with_tools\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8030a184",
   "metadata": {},
   "source": [
    "## Practice\n",
    "\n",
    "Use the cell below to run the exercise script once you complete the TODOs in the Python files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742f2016",
   "metadata": {
    "vscode": {
     "languageId": "bash"
    }
   },
   "outputs": [],
   "source": [
    "# Execute the durable agent workflow\n",
    "!cd ../.. && python -m exercises.03_durable_agent.main\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3673ea3",
   "metadata": {},
   "source": [
    "## Stretch Goal\n",
    "\n",
    "- Simulate a failure inside the activity and observe automatic retries.\n",
    "- Add conversation history to maintain multi-turn context.\n",
    "- Implement exponential backoff retry policy for LLM calls."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

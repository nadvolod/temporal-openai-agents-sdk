{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ekQPgGVwQb1a"
   },
   "source": [
    "# Exercise #2 - Adding Durability Exercise [Solution]\n",
    "\n",
    "In the first notebook, you created a research workflow which currently performs research with an LLM and writes it to a PDF. To add a little more pizaz to your research paper, you used AI to generate an image of the research subject.\n",
    "\n",
    "Now, you're going to use Temporal to add durability to this code.\n",
    "\n",
    "In this exercise, you'll:\n",
    "\n",
    "- Transform your LLM calls and your execution of tools to Activities\n",
    "- Use a Temporal Workflow to orchestrate your Activities\n",
    "- Observe how Temporal handles your errors\n",
    "- Debug your error and observe your Workflow Execution successfully complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_uA13X5SYWe"
   },
   "source": [
    "## Setup\n",
    "\n",
    "Before doing the exercise, you need to:\n",
    "\n",
    "- Install necessary dependencies\n",
    "- Create your `.env` file and supply your API key\n",
    "- Load the environment variables\n",
    "- Download and start a local Temporal Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21551,
     "status": "ok",
     "timestamp": 1757727269458,
     "user": {
      "displayName": "Angela Zhou",
      "userId": "04211316506850475003"
     },
     "user_tz": 240
    },
    "id": "m8UH2Il_Sp50",
    "outputId": "be1fb713-1562-40fd-e5c8-3274d77f9b67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.7/92.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.4/278.4 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# We'll first install the necessary packages for this workshop.\n",
    "\n",
    "%pip install --quiet temporalio litellm reportlab python-dotenv requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HXp3VIAdZuhO"
   },
   "source": [
    "### Create a `.env` File\n",
    "\n",
    "Next you'll create a `.env` file to store your API keys.\n",
    "In the file browser on the left, create a new file and name it `.env`.\n",
    "\n",
    "**Note**: It may disappear as soon as you create it. This is because Google Collab hides hidden files (files that start with a `.`) by default.\n",
    "To make this file appear, click the icon that is a crossed out eye and hidden files will appear.\n",
    "\n",
    "Then double click on the `.env` file and add the following line with your API key.\n",
    "\n",
    "```\n",
    "LLM_API_KEY = YOUR_API_KEY\n",
    "LLM_MODEL = \"openai/gpt-4o\"\n",
    "```\n",
    "\n",
    "By default this notebook uses OpenAI's GPT-4o.\n",
    "If you want to use a different LLM provider, look up the appropriate model name [in their documentation](https://docs.litellm.ai/docs/providers) and change the `LLM_MODEL` field and provide your API key.\n",
    "\n",
    "**To perform image generation, you will need an OpenAI key**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tSl-K8ATXLJ3"
   },
   "outputs": [],
   "source": [
    "# Create .env file\n",
    "with open(\".env\", \"w\") as fh:\n",
    "  fh.write(\"LLM_API_KEY = YOUR_API_KEY\\nLLM_MODEL = openai/gpt-4o\")\n",
    "\n",
    "# Now open the file and replace YOUR_API_KEY with your API key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4PU75hvN-Qed"
   },
   "source": [
    "### Add Your LLM API Key **Before** Running the Following Code Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1757727435260,
     "user": {
      "displayName": "Angela Zhou",
      "userId": "04211316506850475003"
     },
     "user_tz": 240
    },
    "id": "fy4s0KTRdWxL",
    "outputId": "a68d8068-e0ed-4278-8cfd-1a5f05ca9b0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key:  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\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables and configure LLM settings\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Get LLM_API_KEY environment variable and print it to make sure that your .env file is properly loaded.\n",
    "LLM_MODEL = os.getenv(\"LLM_MODEL\", \"openai/gpt-4o\")\n",
    "LLM_API_KEY = os.getenv(\"LLM_API_KEY\", None)\n",
    "print(\"API Key: \", LLM_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "90AW0nTB0P2V"
   },
   "source": [
    "### Setting Up the Temporal Service\n",
    "\n",
    "Run the following blocks to setup & enable a local Temporal Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TLHoJlR4R8Au"
   },
   "outputs": [],
   "source": [
    "# allows us to run the Temporal Asyncio event loop within the event loop of Jupyter Notebooks\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2318,
     "status": "ok",
     "timestamp": 1757727445668,
     "user": {
      "displayName": "Angela Zhou",
      "userId": "04211316506850475003"
     },
     "user_tz": 240
    },
    "id": "scrsqIOy0a_8",
    "outputId": "795ce7c7-8142-47f9-b6b6-5428c83b23e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mtemporal:\u001b[0m Downloading Temporal CLI latest\n",
      "\u001b[1mtemporal:\u001b[0m Temporal CLI installed at /root/.temporalio/bin/temporal\n",
      "\u001b[1mtemporal:\u001b[0m For convenience, we recommend adding it to your PATH\n",
      "\u001b[1mtemporal:\u001b[0m If using bash, run echo export PATH=\"\\$PATH:/root/.temporalio/bin\" >> ~/.bashrc\n"
     ]
    }
   ],
   "source": [
    "# Download the Temporal CLI.\n",
    "\n",
    "!curl -sSf https://temporal.download/cli.sh | sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Sure Your Temporal Web UI is Running\n",
    "\n",
    "1. You should have the Temporal Server running in your terminal (run `temporal server start-dev` if not).\n",
    "2. Then in your `Ports` tab on the bottom of this screen, find `8233` and click on the Globe icon to open the Temporal Web UI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iw22wN9wX1Ok"
   },
   "source": [
    "### Optional: Part 1 - Review Your First Workflow\n",
    "\n",
    "**Part 1 is a review of what you just practiced in the workshop. Feel free to skip it if you feel comfortable with the material.**\n",
    "\n",
    "In the content notebook, you defined the Models, Activities, and Workflows. Fill in the missing parts, then run the code below again, and to get practice running a Temporal Workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lSWFzYyb2UBJ"
   },
   "source": [
    "### Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pMHdjdjL2FlT"
   },
   "outputs": [],
   "source": [
    "# TODO: Run this code to load it into the program\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class LLMCallInput:\n",
    "  prompt: str\n",
    "  llm_api_key: str\n",
    "  llm_model: str\n",
    "\n",
    "@dataclass\n",
    "class PDFGenerationInput:\n",
    "  content: str\n",
    "  image_url: str | None = None\n",
    "  filename: str = \"research_pdf\"\n",
    "\n",
    "@dataclass\n",
    "class GenerateReportInput:\n",
    "    prompt: str\n",
    "\n",
    "@dataclass\n",
    "class GenerateReportOutput:\n",
    "    result: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ys60mB8o2Vib"
   },
   "source": [
    "### Activities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2FEDm6EiYKB2"
   },
   "outputs": [],
   "source": [
    "# TODO: Run this code to load it into the program\n",
    "from io import BytesIO\n",
    "\n",
    "import requests\n",
    "from litellm import completion, ModelResponse\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image as RLImage\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib.units import inch\n",
    "\n",
    "from temporalio import activity\n",
    "\n",
    "@activity.defn\n",
    "def llm_call(input: LLMCallInput) -> ModelResponse:\n",
    "    response = completion(\n",
    "      model=input.llm_model,\n",
    "      api_key=input.llm_api_key,\n",
    "      messages=[{ \"content\": input.prompt,\"role\": \"user\"}]\n",
    "    )\n",
    "    return response\n",
    "\n",
    "@activity.defn\n",
    "def create_pdf_activity(input: PDFGenerationInput) -> str:\n",
    "    doc = SimpleDocTemplate(f\"{input.filename}.pdf\", pagesize=letter)\n",
    "\n",
    "    styles = getSampleStyleSheet()\n",
    "    title_style = ParagraphStyle(\n",
    "        'CustomTitle',\n",
    "        parent=styles['Heading1'],\n",
    "        fontSize=24,\n",
    "        spaceAfter=30,\n",
    "        alignment=1\n",
    "    )\n",
    "\n",
    "    story = []\n",
    "    title = Paragraph(\"Research Report\", title_style)\n",
    "    story.append(title)\n",
    "    story.append(Spacer(1, 20))\n",
    "\n",
    "    if input.image_url is not None:\n",
    "      img_response = requests.get(input.image_url)\n",
    "      img_buffer = BytesIO(img_response.content)\n",
    "      img = RLImage(img_buffer, width=5*inch, height=5*inch)\n",
    "      story.append(img)\n",
    "      story.append(Spacer(1, 20))\n",
    "\n",
    "    paragraphs = input.content.split('\\n\\n')\n",
    "    for para in paragraphs:\n",
    "        if para.strip():\n",
    "            p = Paragraph(para.strip(), styles['Normal'])\n",
    "            story.append(p)\n",
    "            story.append(Spacer(1, 12))\n",
    "\n",
    "    doc.build(story)\n",
    "    return input.filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uS8SgW472Xto"
   },
   "source": [
    "### Workflow\n",
    "\n",
    "A Workflow coordinates the execution of your Activities.\n",
    "\n",
    "1. In the first `execute_activity` call, call your `llm_call` Activity.\n",
    "2. In the second `execute_activity` call where you call `create_pdf_activity`, set your Start-to-Close Timeout to be 10 seconds. This is the maximum time allowed for a single attempt of an Activity to execute.\n",
    "3. Run this code block to load it into the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sUuRKXiXYNey"
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from datetime import timedelta\n",
    "\n",
    "from temporalio import workflow\n",
    "\n",
    "# sandboxed=False is a Notebook only requirement. You normally don't do this\n",
    "@workflow.defn(sandboxed=False)\n",
    "class GenerateReportWorkflow:\n",
    "\n",
    "    @workflow.run\n",
    "    async def run(self, input: GenerateReportInput) -> GenerateReportOutput:\n",
    "\n",
    "        llm_call_input = LLMCallInput(prompt=input.prompt, llm_api_key=LLM_API_KEY, llm_model=LLM_MODEL)\n",
    "\n",
    "        research_facts = await workflow.execute_activity(\n",
    "            llm_call,\n",
    "            llm_call_input,\n",
    "            start_to_close_timeout=timedelta(seconds=30),\n",
    "        )\n",
    "\n",
    "        workflow.logger.info(\"Research complete!\")\n",
    "\n",
    "        pdf_generation_input = PDFGenerationInput(content=research_facts[\"choices\"][0][\"message\"][\"content\"])\n",
    "\n",
    "        pdf_filename = await workflow.execute_activity(\n",
    "            create_pdf_activity,\n",
    "            pdf_generation_input,\n",
    "            start_to_close_timeout=timedelta(seconds=10),\n",
    "        )\n",
    "\n",
    "        return GenerateReportOutput(result=f\"Successfully created research report PDF: {pdf_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qlbhDExL4C1n"
   },
   "source": [
    "### Worker\n",
    "\n",
    "Workers wait for tasks to do, such as an Activity or Workflow Task, and execute them.\n",
    "\n",
    "Workers have Workflows and Activities registered to them so the Worker knows what to execute. \n",
    "1. Pass in your `llm_call` and `create_pdf_activity` Activities into the list so that they are registered to the Worker.\n",
    "2. Run this code block to load it into the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MRaj3kXa4Bpt"
   },
   "outputs": [],
   "source": [
    "from temporalio.client import Client\n",
    "from temporalio.worker import Worker\n",
    "import concurrent.futures\n",
    "\n",
    "async def run_worker() -> None:\n",
    "\n",
    "    # Create client connected to server at the given address\n",
    "    client = await Client.connect(\"localhost:7233\", namespace=\"default\")\n",
    "\n",
    "    # Run the Worker\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=100) as activity_executor:\n",
    "        worker = Worker(\n",
    "            client,\n",
    "            task_queue=\"research\", # the task queue the Worker is polling\n",
    "            workflows=[GenerateReportWorkflow], # register the Workflow\n",
    "            activities=[llm_call, create_pdf_activity], # register the Activities\n",
    "            activity_executor=activity_executor\n",
    "        )\n",
    "\n",
    "        print(f\"Starting the worker....\")\n",
    "        await worker.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BzJrRRh_IrhO"
   },
   "outputs": [],
   "source": [
    "# Start a new worker\n",
    "worker = asyncio.create_task(run_worker())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MlSHFgmG70f-"
   },
   "source": [
    "### Client\n",
    "\n",
    "You request execution of your Workflow by using a Temporal Client.\n",
    "\n",
    "1. In the Client that you specfiy your Workflow to run, the data, you need to specify a Task Queue. This Task Queue must exactly match the Task Queue specified in the Worker.\n",
    "2. Run this code to load it into the program.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7586,
     "status": "ok",
     "timestamp": 1757727517843,
     "user": {
      "displayName": "Angela Zhou",
      "userId": "04211316506850475003"
     },
     "user_tz": 240
    },
    "id": "cJMyyRU97oTj",
    "outputId": "9d21e45f-4ecf-4a42-f27e-2d6cb53bf253"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Research Report Generator!\n",
      "Enter your research topic or question: Give me facts about elephants\n",
      "Started workflow. Workflow ID: generate-research-report-workflow, RunID 019940b9-6c36-758f-98c0-d14f26a0eb35\n"
     ]
    }
   ],
   "source": [
    "from temporalio.client import Client\n",
    "import uuid\n",
    "\n",
    "# Create client connected to server at the given address\n",
    "client = await Client.connect(\"localhost:7233\", namespace=\"default\")\n",
    "\n",
    "print(\"Welcome to the Research Report Generator!\")\n",
    "prompt = input(\"Enter your research topic or question: \").strip()\n",
    "\n",
    "if not prompt:\n",
    "    prompt = \"Give me 5 fun and fascinating facts about tardigrades. Make them interesting and educational!\"\n",
    "    print(f\"No prompt entered. Using default: {prompt}\")\n",
    "\n",
    "# Asynchronous start of a Workflow\n",
    "handle = await client.start_workflow(\n",
    "    GenerateReportWorkflow,\n",
    "    GenerateReportInput(prompt=prompt),\n",
    "    id=f\"generate-research-report-workflow-{uuid.uuid4()}\", # user-defined Workflow identifier, which typically has some business meaning\n",
    "    task_queue=\"research\",  # the task-queue that your Worker is polling\n",
    ")\n",
    "\n",
    "print(f\"Started workflow. Workflow ID: {handle.id}, RunID {handle.result_run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YTY339F9EuhQ"
   },
   "source": [
    "### Review the Workflow Execution in the Web UI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To run the Temporal Server in this exercise environment**:\n",
    "1. You should have the Temporal Server running in your terminal (run `temporal server start-dev` if not).\n",
    "2. Then in your `Ports` tab on the bottom of this screen, find `8233` and click on the Globe icon to open the Temporal Web UI.\n",
    "\n",
    "**Refresh your Web UI.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to kill the current Worker\n",
    "x = worker.cancel()\n",
    "\n",
    "if x:\n",
    "  print(\"Worker killed\")\n",
    "else:\n",
    "  print(\"Worker was not running. Nothing to kill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2BE_tNaFU_dP"
   },
   "source": [
    "### Part 2 - Getting the Subject from Our Past Prompt by Calling an Activity\n",
    "\n",
    "In this exercise you'll:\n",
    "\n",
    "- Add a call to the `llm_call` Activity in the Workflow\n",
    "- Modify the subsequent Activity call to pass the topic to the `create_pdf` Activity\n",
    "- Start the Worker\n",
    "- Run the Workflow and see it perform a research task, and create a file where the name of the file is the topic of the research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orchestrate your Activities\n",
    "\n",
    "1. In your Workflow, call the `llm_call` Activity as the first executed Activity.\n",
    "2. When you execute your `llm_call` Activity, pass in the `subject_input` as a parameter.\n",
    "3. When you execute your `llm_call` Activity, set your Start-to-Close Timeout to be 30 seconds.\n",
    "4. In your Workflow, call the `create_pdf` Activity as the second executed Activity.\n",
    "5. When you execute your `create_pdf` Activity, pass in the `pdf_generation_input` as a parameter.\n",
    "6. When you execute your `llm_call` Activity, set your Start-to-Close Timeout to be 10 seconds.\n",
    "7. Run the code block to load it into the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pOlBt5yd5W36"
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from datetime import timedelta\n",
    "\n",
    "from temporalio import workflow\n",
    "\n",
    "# sandboxed=False is a Notebook only requirement. You normally don't do this\n",
    "@workflow.defn(sandboxed=False)\n",
    "class GenerateReportWorkflow:\n",
    "\n",
    "    @workflow.run\n",
    "    async def run(self, input: GenerateReportInput) -> GenerateReportOutput:\n",
    "\n",
    "        research_input = LLMCallInput(prompt=input.prompt, llm_api_key=LLM_API_KEY, llm_model=LLM_MODEL)\n",
    "\n",
    "        research_facts = await workflow.execute_activity(\n",
    "            llm_call,\n",
    "            research_input,\n",
    "            start_to_close_timeout=timedelta(seconds=30), # maximum duration for the LLM call to complete\n",
    "        )\n",
    "\n",
    "        workflow.logger.info(\"Research complete!\")\n",
    "\n",
    "        # Added the subject prompt\n",
    "        subject_prompt = f\"What is the main topic of this sentence? Respond with only the topic in a single word or short phrase. No explanation. The sentence is: {input.prompt}\"\n",
    "\n",
    "        # Created an object to pass to the Activity\n",
    "        subject_input = LLMCallInput(prompt=subject_prompt, llm_api_key=LLM_API_KEY, llm_model=LLM_MODEL)\n",
    "\n",
    "        # Called the llm_call Activity again with a new prompt\n",
    "        topic_call = await workflow.execute_activity(\n",
    "            llm_call,\n",
    "            subject_input,\n",
    "            start_to_close_timeout=timedelta(seconds=30),\n",
    "        )\n",
    "\n",
    "        # Extracted the topic from the response\n",
    "        topic = topic_call[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "        # Passed in the topic as the filename so it can be used to name the file\n",
    "        pdf_generation_input = PDFGenerationInput(content=research_facts[\"choices\"][0][\"message\"][\"content\"], filename=topic)\n",
    "\n",
    "        pdf_filename = await workflow.execute_activity(\n",
    "            create_pdf_activity,\n",
    "            pdf_generation_input,\n",
    "            start_to_close_timeout=timedelta(seconds=10),\n",
    "        )\n",
    "\n",
    "        return GenerateReportOutput(result=f\"Successfully created research report PDF: {pdf_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XRFAWSBa4QZd"
   },
   "outputs": [],
   "source": [
    "# Kill any previous workers that may still be running\n",
    "x = worker.cancel()\n",
    "\n",
    "# Start a new worker\n",
    "worker = asyncio.create_task(run_worker())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4792,
     "status": "ok",
     "timestamp": 1757727599919,
     "user": {
      "displayName": "Angela Zhou",
      "userId": "04211316506850475003"
     },
     "user_tz": 240
    },
    "id": "kgtTTapM6CNy",
    "outputId": "86a1a9b5-3269-4f31-a96e-f2367a6f5768"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Research Report Generator!\n",
      "Enter your research topic or question: give me facts about elephants\n",
      "Started workflow. Workflow ID: generate-research-report-workflow, RunID 019940ba-acf2-79f2-95a6-fefe18594bbc\n"
     ]
    }
   ],
   "source": [
    "# Execute your Workflow\n",
    "import uuid\n",
    "\n",
    "client = await Client.connect(\"localhost:7233\", namespace=\"default\")\n",
    "\n",
    "print(\"Welcome to the Research Report Generator!\")\n",
    "prompt = input(\"Enter your research topic or question: \").strip()\n",
    "\n",
    "if not prompt:\n",
    "    prompt = \"Give me 5 fun and fascinating facts about tardigrades. Make them interesting and educational!\"\n",
    "    print(f\"No prompt entered. Using default: {prompt}\")\n",
    "\n",
    "# Asynchronous start of a Workflow\n",
    "handle = await client.start_workflow(\n",
    "    GenerateReportWorkflow,\n",
    "    GenerateReportInput(prompt=prompt),\n",
    "    id=f\"generate-research-report-workflow-{uuid.uuid4()}\",\n",
    "    task_queue=\"research\",\n",
    ")\n",
    "\n",
    "print(f\"Started workflow. Workflow ID: {handle.id}, RunID {handle.result_run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zaIYuART6KKY"
   },
   "source": [
    "### Watch the Execuction in the Web UI\n",
    "\n",
    "Refresh the Web UI and watch the execution. Find the following items in the Web UI:\n",
    "\n",
    "- What was the output of the `llm_call` Activity?\n",
    "- What was the output of the `create_pdf` Activity?\n",
    "- What was the output of the Workflow Execution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HNrBOqdISGll"
   },
   "source": [
    "### Part 3 - Convert the Image Creation Function to an Activity and Recover from an Error\n",
    "\n",
    "In the first exercise, you called a function to create an image of the topic of the prompt. In this exercise you'll:\n",
    "\n",
    "- Update this function to be an Activity\n",
    "- Register the Activity with the Worker\n",
    "- Call the Activity from within the Workflow\n",
    "- Test your Workflow\n",
    "- Observe your retry policy in your Activity\n",
    "- Fix your error and watch your Workflow successfully complete.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "85kUXKuDGbWl"
   },
   "outputs": [],
   "source": [
    "# Add a new model for Activity input\n",
    "# Run this code block to load it into the program.\n",
    "@dataclass\n",
    "class GenerateImageInput:\n",
    "    topic: str\n",
    "    llm_api_key: str\n",
    "    llm_model: str = \"dall-e-3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nRYQtg_fO-GD"
   },
   "outputs": [],
   "source": [
    "# Step 1: Add the @activity.defn decorator\n",
    "# Step 2: Even though we added an intentional error in this Activity, run it to load it into the program.\n",
    "# Step 3: Consider this: What do you think will happen to the Workflow in Temporal with the error in the Activity?\n",
    "from litellm import image_generation\n",
    "from temporalio import activity\n",
    "from temporalio.exceptions import ApplicationError\n",
    "\n",
    "@activity.defn\n",
    "def generate_ai_image(input: GenerateImageInput) -> ModelResponse:\n",
    "\n",
    "    image_prompt = f\"A cute, natural image of {input.topic}.\"\n",
    "\n",
    "    response = image_generation(\n",
    "        prompt=image_prompt,\n",
    "        model=input.llm_model,\n",
    "        api_key=input.llm_api_key\n",
    "    )\n",
    "\n",
    "    raise ApplicationError( # We are going to intentionally throw an error in your Activity to observe retries.\n",
    "        error_message=\"intentional error\",\n",
    "    )\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CVHUEi9kGuIS"
   },
   "outputs": [],
   "source": [
    "# Step 1: Decorate your `run` method with `@workflow.run`\n",
    "# Step 2: Call your `generate_ai_image` from your Workflow.\n",
    "# Step 3: Run the code block to load it into the program.\n",
    "import asyncio\n",
    "from datetime import timedelta\n",
    "\n",
    "from temporalio import workflow\n",
    "\n",
    "# sandboxed=False is a Notebook only requirement. You normally don't do this\n",
    "@workflow.defn(sandboxed=False)\n",
    "class GenerateReportWorkflow:\n",
    "\n",
    "    @workflow.run\n",
    "    async def run(self, input: GenerateReportInput) -> GenerateReportOutput:\n",
    "\n",
    "        research_input = LLMCallInput(prompt=input.prompt, llm_api_key=LLM_API_KEY, llm_model=LLM_MODEL)\n",
    "\n",
    "        research_facts = await workflow.execute_activity(\n",
    "            llm_call,\n",
    "            research_input,\n",
    "            start_to_close_timeout=timedelta(seconds=30),\n",
    "        )\n",
    "\n",
    "        workflow.logger.info(\"Research complete!\")\n",
    "\n",
    "        subject_prompt = f\"What is the main topic of this sentence? Respond with only the topic in a single word or short phrase. No explanation. The sentence is: {input.prompt}\"\n",
    "        subject_input = LLMCallInput(prompt=subject_prompt, llm_api_key=LLM_API_KEY, llm_model=LLM_MODEL)\n",
    "\n",
    "        topic_call = await workflow.execute_activity(\n",
    "            llm_call,\n",
    "            subject_input,\n",
    "            start_to_close_timeout=timedelta(seconds=30),\n",
    "        )\n",
    "\n",
    "        topic = topic_call[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "        # Used the new GenerateImageInput dataclass to create the input object for the Activity\n",
    "        image_input = GenerateImageInput(topic=topic, llm_api_key=LLM_API_KEY)\n",
    "\n",
    "        # Called the new generate_ai_image Activity, passing in the image_input parameter made above\n",
    "        ai_image = await workflow.execute_activity(\n",
    "            generate_ai_image,\n",
    "            image_input,\n",
    "            start_to_close_timeout=timedelta(seconds=30),\n",
    "        )\n",
    "\n",
    "        # Exctract the image_url form the Activity call\n",
    "        image_url = ai_image[\"data\"][0][\"url\"]\n",
    "\n",
    "        # Add the image_url parameter to the PDF Generation so the image is included\n",
    "        pdf_generation_input = PDFGenerationInput(content=research_facts[\"choices\"][0][\"message\"][\"content\"], image_url=image_url, filename=topic)\n",
    "\n",
    "        pdf_filename = await workflow.execute_activity(\n",
    "            create_pdf_activity,\n",
    "            pdf_generation_input,\n",
    "            start_to_close_timeout=timedelta(seconds=10),\n",
    "        )\n",
    "\n",
    "        return GenerateReportOutput(result=f\"Successfully created research report PDF: {pdf_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mRD_jfd8HtUS"
   },
   "source": [
    "### Register the Activity with the Worker\n",
    "\n",
    "Don't forget, you have to register your code with the Worker for it to be executed!\n",
    "1. Register your GenerateReportWorkflow\n",
    "2. Register your `llm_call`, `create_pdf_activity, `generate_ai_image` Activities\n",
    "3. Run the code block to load it into the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ujj6pAGoHsoz"
   },
   "outputs": [],
   "source": [
    "from temporalio.client import Client\n",
    "from temporalio.worker import Worker\n",
    "import concurrent.futures\n",
    "\n",
    "async def run_worker() -> None:\n",
    "\n",
    "    client = await Client.connect(\"localhost:7233\", namespace=\"default\")\n",
    "\n",
    "    # Run the Worker\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=100) as activity_executor:\n",
    "        worker = Worker(\n",
    "            client,\n",
    "            task_queue=\"research\",\n",
    "            workflows=[GenerateReportWorkflow],\n",
    "            # Registered the new Activity here\n",
    "            activities=[llm_call, create_pdf_activity, generate_ai_image],\n",
    "            activity_executor=activity_executor\n",
    "        )\n",
    "\n",
    "        print(f\"Starting the worker....\")\n",
    "        await worker.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KBAre4bDHVw7"
   },
   "outputs": [],
   "source": [
    "# Kill any previous workers that may still be running\n",
    "x = worker.cancel()\n",
    "\n",
    "# Start a new worker\n",
    "worker = asyncio.create_task(run_worker())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4811,
     "status": "ok",
     "timestamp": 1757727773438,
     "user": {
      "displayName": "Angela Zhou",
      "userId": "04211316506850475003"
     },
     "user_tz": 240
    },
    "id": "ySug_ag_HR-H",
    "outputId": "251b2695-b300-4a33-815e-d1235457ace3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Research Report Generator!\n",
      "Enter your research topic or question: give me facts about elephants\n",
      "Started workflow. Workflow ID: generate-research-report-workflow, RunID 019940bd-52bf-7e93-a601-d5b788afa829\n"
     ]
    }
   ],
   "source": [
    "# Run the Workflow\n",
    "import uuid\n",
    "\n",
    "client = await Client.connect(\"localhost:7233\", namespace=\"default\")\n",
    "\n",
    "print(\"Welcome to the Research Report Generator!\")\n",
    "prompt = input(\"Enter your research topic or question: \").strip()\n",
    "\n",
    "if not prompt:\n",
    "    prompt = \"Give me 5 fun and fascinating facts about tardigrades. Make them interesting and educational!\"\n",
    "    print(f\"No prompt entered. Using default: {prompt}\")\n",
    "\n",
    "# Asynchronous start of a Workflow\n",
    "handle = await client.start_workflow(\n",
    "    GenerateReportWorkflow,\n",
    "    GenerateReportInput(prompt=prompt),\n",
    "    id=f\"generate-research-report-workflow-{uuid.uuid4()}\",\n",
    "    task_queue=\"research\",\n",
    ")\n",
    "\n",
    "print(f\"Started workflow. Workflow ID: {handle.id}, RunID {handle.result_run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Refresh your Web UI**.\n",
    "\n",
    "1. You should have the Temporal Server running in your terminal (run `temporal server start-dev` if not).\n",
    "2. Then in your `Ports` tab on the bottom of this screen, find `8233` and click on the Globe icon to open the Temporal Web UI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yOtw63BuPpI9"
   },
   "source": [
    "### Observing Retries\n",
    "\n",
    "You should see that the `generate_ai_image` Activity is retrying over and over because of the intentional error we added in the Activity..\n",
    "\n",
    "In our case, this is just an error we are intentionally throwing, but this could just as easily be an internal service that isn't responding, a network outage, an application crashing, or more.\n",
    "\n",
    "Find the answers to these by expanding the `Pending Activity` in your Event History.\n",
    "- What is the message in the Pending Activity?\n",
    "- What retry attempt is it on?\n",
    "- How many seconds until the next retry attempt?\n",
    "\n",
    "Let's fix the error by commenting it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DSFNObu9QCrW"
   },
   "outputs": [],
   "source": [
    "# Step 1: Comment out the intentional error\n",
    "# Step 2: Run the code block to load it into the program\n",
    "from litellm import image_generation\n",
    "from temporalio import activity\n",
    "from temporalio.exceptions import ApplicationError\n",
    "\n",
    "@activity.defn\n",
    "def generate_ai_image(input: GenerateImageInput) -> ModelResponse:\n",
    "\n",
    "    image_prompt = f\"A cute, natural image of {input.topic}.\"\n",
    "\n",
    "    response = image_generation(\n",
    "        prompt=image_prompt,\n",
    "        model=input.llm_model,\n",
    "        api_key=input.llm_api_key\n",
    "    )\n",
    "\n",
    "    # raise ApplicationError( # We are going to intentionally throw an error in your Activity to observe retries.\n",
    "    #     error_message=\"intentional error\",\n",
    "    # )\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4m5KPfDWQJPo"
   },
   "outputs": [],
   "source": [
    "# Kill any previous workers that may still be running\n",
    "x = worker.cancel()\n",
    "\n",
    "# Start a new worker\n",
    "worker = asyncio.create_task(run_worker())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SZDJD8CuQU7w"
   },
   "source": [
    "### Observing Workflow Completion\n",
    "\n",
    "Go back to your Web UI, and we’ll now see that the Workflow Execution completes successfully! Temporal preserved its Workflow state through failures and replayed with our updated code, continuing exactly where we left off.\n",
    "\n",
    "This is the power of Temporal - your critical business processes are guaranteed to complete with no manual recovery, no lost data, and no duplicate operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kill any worker to prepare for the next chapter.\n",
    "x = worker.cancel()\n",
    "\n",
    "if x:\n",
    "  print(\"Worker killed\")\n",
    "else:\n",
    "  print(\"Worker was not running. Nothing to kill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's Next?\n",
    "\n",
    "This workshop introduced you to the **concept** of Temporal. Further your learning with these resources:\n",
    "\n",
    "### Resources\n",
    "\n",
    "- Our free [Temporal 102 Course](https://learn.temporal.io/courses/temporal_102/python/) which covers these concepts (Workflows, Activities, Replay, and more) in more detail\n",
    "- A Temporal [tutorial in the Python SDK](https://learn.temporal.io/getting_started/python/hello_world_in_python/) that showcases how to get started with Temporal"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "history_visible": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

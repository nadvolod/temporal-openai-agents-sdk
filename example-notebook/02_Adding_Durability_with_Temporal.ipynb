{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iy6hs6HQZY-Z"
   },
   "source": [
    "# Adding Durability with Temporal\n",
    "\n",
    "You've just built a research application that generates PDF reports. It works perfectly—until it doesn't.\n",
    "\n",
    "Imagine this: Your application conducts expensive research through an LLM call (costing time and money), but then **crashes** during PDF generation due to a network outage. When you restart, everything is lost. You're back to the beginning, paying for the same LLM call again, making your users wait, and burning through your API budget.\n",
    "\n",
    "As these workflows grow more complex—chaining multiple LLM calls, database queries, external APIs—the problem compounds. Every failure means starting over completely.\n",
    "\n",
    "In this section, we'll solve this problem by making your application durable. You'll learn how to build GenAI applications that survive failures, recover automatically, and never lose progress."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OKIuzLjvucLf"
   },
   "source": [
    "### Challenges of GenAI Applications\n",
    "\n",
    "* Networks can be flakey\n",
    "* LLMs are often rate limited\n",
    "* Tool resources (APIs and databases) go down\n",
    "* LLMs are inherently non-deterministic\n",
    "* How do we scale these applications?\n",
    "* What happens when they take a long time to finish?\n",
    "…\n",
    "What else?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JQOR9QLGZ_hw"
   },
   "source": [
    "### These Aren't New Problems\n",
    "\n",
    "The challenges you just identified? They're the same problems we've been solving in distributed systems for decades:\n",
    "\n",
    "**Your Research Application in Production Reality:**\n",
    "* **LLM API call** - External service that can timeout, rate limit, or be down.\n",
    "* **PDF generation** - File system operation that can fail due to disk space\n",
    "* **User input/output** - Network operations that can be interrupted\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "01ZkJPjC7njg"
   },
   "source": [
    "### GenAI Applications are Distributed Systems!\n",
    "\n",
    "**This is a distributed system!** Your \"simple\" application is actually:\n",
    "* Multiple network calls to external services\n",
    "* File system operations\n",
    "* State that needs to persist across failures\n",
    "* Coordination between different steps\n",
    "\n",
    "**The challenge:** Traditional distributed systems tools weren't designed for AI workflows. They don't understand expensive LLM calls, context windows, or long-term state management.\n",
    "\n",
    "**The good news:** You can use a platform that guarantees the _reliable execution_ of your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Normal Execution Gives Us\n",
    "\n",
    "* Every failure means restarting from scratch\n",
    "* Expensive LLM calls are repeated unnecessarily\n",
    "* User experience becomes frustrating and unreliable\n",
    "* No way to resume from where you left off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Developers Actually Want\n",
    "\n",
    "* \"Just fix the disk issue and generate the PDF from the research you already have.\"\n",
    "* \"Don't make me pay for the same LLM call twice!\"\n",
    "* \"Don't lose my work because of a simple file system error!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a_1jsgtvaLJ1"
   },
   "source": [
    "### Your Report Generation Application Needs Durability\n",
    "\n",
    "Recall your research application from Notebook 1? Here's what happens in production:\n",
    "\n",
    "**Scenario:** User asks for research on \"sustainable energy trends\":\n",
    "\n",
    "1. LLM call succeeds - generates comprehensive research content ($2.50 in API costs)\n",
    "2. PDF generation fails - disk full, permission error, or process crash\n",
    "3. User has to start over completely - losing expensive work and time\n",
    "\n",
    "We need a way to make our AI applications resilient to these failures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducing Temporal\n",
    "\n",
    "- Technology and open source project that delivers resilience for distributed systems in a novel way.\n",
    "- Supports a programming model that allows developers to code the **happy path**, while the platform provides services that compensate for a wide range of distributed system failures.\n",
    "- Platform comes in the form of a service + SDKs\n",
    "- SDK is available for Go, Java, Python, PHP, Typescript, .Net, Ruby"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Make Your GenAI Application Durable\n",
    "\n",
    "We're about to transform your simple research application into a durable one. Here's what changes:\n",
    "\n",
    "* Your tools will become crash-proof\n",
    "* Automatic retries and recovery\n",
    "* State persistence\n",
    "\n",
    "This results in a process such as:\n",
    "LLM Decision → Tool A → Result X (Saved in history, then on replay, same result X will result in the same next decision) → Next Decision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What stays the same\n",
    "\n",
    "* Your core logic (LLM call → PDF generation)\n",
    "* Your inputs and outputs\n",
    "* Your business requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package Our Inputs & Outputs for Ease of Management\n",
    "\n",
    "For ease of use, evolution of parameters, and type checking, Temporal recommends passing and returning a single object from functions. `dataclass` is the recommended structure here, but anything serializable will work.\n",
    "\n",
    "_Read more about inputs and outputs in [this chapter](https://temporal.talentlms.com/unit/view/id:2822) of our free Temporal 102 course._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Run this code block to load it into the program\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class LLMCallInput:\n",
    "  prompt: str\n",
    "\n",
    "@dataclass\n",
    "class PDFGenerationInput:\n",
    "  content: str\n",
    "  filename: str = \"research_pdf.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is an Activity?\n",
    "\n",
    "* Functions that are making external calls are “wrapped” as activities\n",
    "* An Activity is a function that is prone to failure and/or non-deterministic.\n",
    "* Temporal requires all non-deterministic code be run in an Activity\n",
    "\n",
    "Examples:\n",
    "  - External API calls - LLM requests, web scraping, database queries\n",
    "  - File system operations - Reading documents, writing reports, managing storage\n",
    "  - Network operations - HTTP requests, email sending, data transfers\n",
    "  - Resource-intensive computations - Image processing, data analysis, model inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Activities Give You\n",
    "\n",
    "* [**Automatic retries**](https://docs.temporal.io/develop/python/failure-detection#activity-retries) when external code fails\n",
    "* [**Timeout handling**](https://docs.temporal.io/develop/python/failure-detection#activity-timeouts) for slow operations and detecting failures\n",
    "* **Detailed visibility** of execution, including inputs/outputs for debugging\n",
    "* **Automatic checkpoints** - if your workflow crashes, Activities aren't re-executed. Instead, your Workflow continues from the last known good state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks/Tools become Activities\n",
    "\n",
    "- To turn a function/method into an Activity, add the `@activity.defn` decorator.\n",
    "- Package activity arguments into a data structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As an Activity, Your LLM Call is Now:\n",
    "* Protected against API timeouts\n",
    "* Automatically retried with backoff\n",
    "* Observable for debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As an Activity, Your PDF Generation is Now:\n",
    "* Protected against file system errors\n",
    "* Automatically retried if temporary failures\n",
    "* Tracked for completion verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Create Activities.\n",
    "\n",
    "But first, let's set up our notebook. Run the following code blocks to install various packages and tools necessary to run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll first install the necessary packages for this workshop.\n",
    "\n",
    "%pip install --quiet temporalio litellm reportlab python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a `.env` File\n",
    "\n",
    "Next you'll create a `.env` file to store your API keys.\n",
    "In the file browser on the left, create a new file and name it `.env`.\n",
    "Note that this file doesn't persist across notebooks or sesions.\n",
    "\n",
    "**Note**: It may disappear as soon as you create it. This is because Google Collab hides hidden files (files that start with a `.`) by default.\n",
    "To make this file appear, click the icon that is a crossed out eye and hidden files will appear.\n",
    "\n",
    "Then double click on the `.env` file and add the following line with your API key.\n",
    "\n",
    "```\n",
    "LLM_API_KEY = YOUR_API_KEY\n",
    "LLM_MODEL = \"openai/gpt-4o\"\n",
    "```\n",
    "\n",
    "By default this notebook uses OpenAI's GPT-4o.\n",
    "If you want to use a different LLM provider, look up the appropriate model name [in the documentation](https://docs.litellm.ai/docs/providers) and change the `LLM_MODEL` field and provide your API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create .env file\n",
    "with open(\".env\", \"w\") as fh:\n",
    "  fh.write(\"LLM_API_KEY = YOUR_API_KEY\\nLLM_MODEL = openai/gpt-4o\")\n",
    "\n",
    "# Now open the file and replace YOUR_API_KEY with your API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables and configure LLM settings\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Get LLM_API_KEY environment variable and print it to make sure that your .env file is properly loaded.\n",
    "LLM_MODEL = os.getenv(\"LLM_MODEL\", \"openai/gpt-4o\")\n",
    "LLM_API_KEY = os.getenv(\"LLM_API_KEY\", None)\n",
    "print(\"LLM API Key\", LLM_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This allows us to run the Temporal Asyncio event loop within the event loop of Jupyter Notebooks\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running this will download the Temporal CLI, which we need for this workshop.\n",
    "\n",
    "!curl -sSf https://temporal.download/cli.sh | sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "doN_2Wzganj5"
   },
   "outputs": [],
   "source": [
    "# Let's Create Activities\n",
    "# TODO: Run this code block to load it into the program\n",
    "from temporalio import activity\n",
    "from litellm import completion, ModelResponse\n",
    "\n",
    "@activity.defn\n",
    "def llm_call(input: LLMCallInput) -> ModelResponse:\n",
    "    response = completion(\n",
    "      model=LLM_MODEL,\n",
    "      api_key=LLM_API_KEY,\n",
    "      messages=[{ \"content\": input.prompt,\"role\": \"user\"}]\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_OOx3-Y4lkkW"
   },
   "outputs": [],
   "source": [
    "# Step 1: Make the code an Activity. Look at the cell below for the solution.\n",
    "# Step 2: Now run the code to load it into the program\n",
    "\n",
    "from temporalio import activity\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "\n",
    "# TODO Add the Acticity decorator to make this function a Temporal Activity\n",
    "def create_pdf_activity(input: PDFGenerationInput) -> str:\n",
    "    print(\"Creating PDF document...\")\n",
    "\n",
    "    doc = SimpleDocTemplate(input.filename, pagesize=letter)\n",
    "    styles = getSampleStyleSheet()\n",
    "    title_style = ParagraphStyle(\n",
    "        'CustomTitle',\n",
    "        parent=styles['Heading1'],\n",
    "        fontSize=24,\n",
    "        spaceAfter=30,\n",
    "        alignment=1\n",
    "    )\n",
    "\n",
    "    story = []\n",
    "    title = Paragraph(\"Research Report\", title_style)\n",
    "    story.append(title)\n",
    "    story.append(Spacer(1, 20))\n",
    "    paragraphs = input.content.split('\\n\\n')\n",
    "    for para in paragraphs:\n",
    "        if para.strip():\n",
    "          p = Paragraph(para.strip(), styles['Normal'])\n",
    "          story.append(p)\n",
    "          story.append(Spacer(1, 12))\n",
    "\n",
    "    doc.build(story)\n",
    "\n",
    "    print(f\"SUCCESS! PDF created: {input.filename}\")\n",
    "    return input.filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Run this cell to load and display the solution\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Markdown\n",
    "import os\n",
    "\n",
    "notebook_dir = Path(os.getcwd())\n",
    "solution_file = notebook_dir / \"Solutions_02_Adding_Durability_with_Temporal\" / \"create_pdf_activity_solution.py\"\n",
    "\n",
    "code = solution_file.read_text()\n",
    "\n",
    "print(\"Solution loaded:\")\n",
    "display(Markdown(f\"```python\\n{code}\\n```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KF98wlHSKnak"
   },
   "source": [
    "### Activities Are Called from Workflows\n",
    "\n",
    "- You orchestrate the execution of your Activities from within a [Workflow](https://docs.temporal.io/workflow-definition#workflow-definition).\n",
    "- Workflows contain the decision-making flow, but Activities perform the actual work.\n",
    "- Each Activity call is recorded in the workflow history with inputs and outputs\n",
    "- Workflows can wait for Activity completion, handle failures, and make decisions based on results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Workflow\n",
    "\n",
    "* Activities are orchestrated within a Temporal Workflow.\n",
    "* Workflows must **not** make API calls, file system calls, or anything non-deterministic. That is what Activities are for.\n",
    "* Workflows are async, and you define them as a class decorated with the `@workflow.defn` decorator.\n",
    "* Every Workflow has a **single** entry point, which is an `async` method decorated with `@workflow.run`.\n",
    "\n",
    "<img src=\"https://i.postimg.cc/yxW08BHD/activity-workflow-chain.png\" width=\"200\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NlWk6DY63Ehg"
   },
   "source": [
    "### More Input/Output Packaging\n",
    "\n",
    "Just like with Activities, Temporal recommends passing a single object to the Workflow for input and returning a single object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0mesIIXMMkNG"
   },
   "outputs": [],
   "source": [
    "# TODO: Run this code block to load it into the program\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class GenerateReportInput:\n",
    "    prompt: str\n",
    "\n",
    "@dataclass\n",
    "class GenerateReportOutput:\n",
    "    result: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3tq0aUW3OQkS"
   },
   "outputs": [],
   "source": [
    "# Step 1: Add your `@workflow.run` decorator\n",
    "# Step 2:Notice how the Workflow calls the `llm_call` Activity. \n",
    "# Step 3: Follow the pattern to call the `create_pdf_activity`.\n",
    "# Step 4: Pass in your pdf_generation_input\n",
    "# Step 5: A Start-to-Close timeout is the maximum amount of time a single Activity Execution can take. We recommend always setting this timeout.\n",
    "# Set a Start-to-Close timeout of 10 seconds for the `create_pdf_activity`.\n",
    "# Step 6: Run this code block to load it into the program\n",
    "from datetime import timedelta\n",
    "from temporalio import workflow\n",
    "\n",
    "# sandboxed=False is a Notebook only requirement. You normally don't do this\n",
    "@workflow.defn(sandboxed=False)\n",
    "class GenerateReportWorkflow:\n",
    "\n",
    "    # TODO: Add your `@workflow.run` decorator here\n",
    "    async def run(self, input: GenerateReportInput) -> GenerateReportOutput:\n",
    "\n",
    "        llm_call_input = LLMCallInput(prompt=input.prompt)\n",
    "\n",
    "        research_facts = await workflow.execute_activity(\n",
    "            llm_call,\n",
    "            llm_call_input,\n",
    "            start_to_close_timeout=timedelta(seconds=30), # maximum amount of time a single Activity Execution can take.\n",
    "        )\n",
    "\n",
    "        workflow.logger.info(\"Research complete!\")\n",
    "\n",
    "        pdf_generation_input = PDFGenerationInput(content=research_facts[\"choices\"][0][\"message\"][\"content\"])\n",
    "\n",
    "        pdf_filename = await workflow.execute_activity(\n",
    "            # TODO: Call the create_pdf_activity here\n",
    "            # TODO: Pass in your pdf_generation_input\n",
    "            # TODO: Set the Start-to-Close timeout of 10 seconds here\n",
    "        )\n",
    "\n",
    "        return GenerateReportOutput(result=f\"Successfully created research report PDF: {pdf_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Run this cell to load and display the solution\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Markdown\n",
    "import os\n",
    "\n",
    "notebook_dir = Path(os.getcwd())\n",
    "solution_file = notebook_dir / \"Solutions_02_Adding_Durability_with_Temporal\" / \"generatereportworkflow_solution.py\"\n",
    "\n",
    "code = solution_file.read_text()\n",
    "\n",
    "print(\"Solution loaded:\")\n",
    "display(Markdown(f\"```python\\n{code}\\n```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q0gKu3eSQxbO"
   },
   "source": [
    "### Temporal Workers\n",
    "\n",
    "* Temporal Workflows are run on [Workers](https://docs.temporal.io/workers)\n",
    "* Workers wait for tasks to do, such as an Activity or Workflow Task, and execute them.\n",
    "\n",
    "_Read more about how Workers execute Workflow and Activity tasks in [this chapter](https://temporal.talentlms.com/unit/view/id:2455) of our free Temporal 101 course._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running a Worker\n",
    "\n",
    "* Workers have Workflows and Activities registered to them so the Worker knows what to execute.\n",
    "* Workers find tasks by listenting on a Task Queue\n",
    "* Any Worker can pick up a registered Workflow or Activity\n",
    "\n",
    "The Worker architecture turns your monolith into a modular, event driven application!\n",
    "\n",
    "<img src=\"https://i.postimg.cc/dQZZNGPg/worker-architecture.png\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running a Temporal Service\n",
    "\n",
    "* The Temporal Service brings it all together\n",
    "* The Temporal Service can be run locally, self-hosted, or you can use Temporal Cloud\n",
    "* The service acts as the supervisor of your Workflows, Activities, and everything else"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Durable Execution\n",
    "\n",
    "Instead of event-driven architecture, define your workflow as code and let the system track exactly where you are. Write for the happy path—no need to manage queues, events, retries, rollbacks, or state checkpoints. With durable execution, you can just focus on business logic.\n",
    "\n",
    "<img src=\"https://i.postimg.cc/635g59w5/durable-execution-example.png\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run the Temporal Server Now in this Exercise Environment**:\n",
    "1. To start the Temporal Server, run `temporal server start-dev` in your terminal.\n",
    "2. Then in your `Ports` tab on the bottom of this screen, find `8233` and click on the Globe icon to open the Temporal Web UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZB5mZ3HxOk6u"
   },
   "outputs": [],
   "source": [
    "# Here is code for our Worker\n",
    "# Step 1: Pass in our `create_pdf_activity` into the list to register them with the Worker\n",
    "# Step 2: Set the task queue that the Worker is polling to be \"research\"\n",
    "# Step 3: Run this codeblock to load it into the program\n",
    "import concurrent.futures\n",
    "from temporalio.client import Client\n",
    "from temporalio.worker import Worker\n",
    "\n",
    "async def run_worker() -> None:\n",
    "    # Create client connected to server at the given address\n",
    "    client = await Client.connect(\"localhost:7233\", namespace=\"default\")\n",
    "\n",
    "    # Run the Worker\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=100) as activity_executor:\n",
    "        worker = Worker(\n",
    "            client,\n",
    "            task_queue=\"\", # TODO Set the task queue that the Worker is polling to be \"research\"\n",
    "            workflows=[GenerateReportWorkflow], # register the Workflow\n",
    "            activities=[llm_call, __], # TODO Pass in your create_pdf_activity to register it\n",
    "            activity_executor=activity_executor\n",
    "        )\n",
    "\n",
    "        print(f\"Starting the worker....\")\n",
    "        await worker.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Run this cell to load and display the solution\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Markdown\n",
    "import os\n",
    "\n",
    "notebook_dir = Path(os.getcwd())\n",
    "solution_file = notebook_dir / \"Solutions_02_Adding_Durability_with_Temporal\" / \"worker_solution.py\"\n",
    "\n",
    "code = solution_file.read_text()\n",
    "\n",
    "print(\"Solution loaded:\")\n",
    "display(Markdown(f\"```python\\n{code}\\n```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FB4oDvu7Nbwm"
   },
   "source": [
    "### Starting the Worker\n",
    "\n",
    "A Workflow can't execute if a Worker isn't running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lZiLuWj_Q0XR"
   },
   "outputs": [],
   "source": [
    "# Due to the limitation of Jupyter Notebooks and Google Collab, this is how\n",
    "# you must start the worker in a Notebook environment\n",
    "import asyncio\n",
    "\n",
    "worker = asyncio.create_task(run_worker())\n",
    "\n",
    "# If you are running this code in a typical Python environment, you can start\n",
    "# the Worker by just calling `asyncio.run`\n",
    "# if __name__ == \"__main__\":\n",
    "#    asyncio.run(run_worker())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executing the Workflow\n",
    "\n",
    "- Temporal Workflows are executed indirectly\n",
    "- Request execution from the Temporal Service\n",
    "- You do this with the [Temporal Client](https://docs.temporal.io/develop/python/temporal-client)\n",
    "\n",
    "<img src=\"https://i.postimg.cc/76Mdqfjd/client.png\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QTOOaYd8UnBL",
    "outputId": "b23a7ac2-7329-436b-cd65-098549037771"
   },
   "outputs": [],
   "source": [
    "# Step 1: Set the Task Queue to be the Task Queue that your Worker is polling\n",
    "# Step 2: Pass in the Workflow you are running \n",
    "# Step 3 Run this code block to load it into the program\n",
    "from temporalio.client import Client\n",
    "import uuid\n",
    "\n",
    "# Create client connected to server at the given address\n",
    "client = await Client.connect(\"localhost:7233\", namespace=\"default\")\n",
    "\n",
    "print(\"Welcome to the Research Report Generator!\")\n",
    "prompt = input(\"Enter your research topic or question: \").strip()\n",
    "\n",
    "if not prompt:\n",
    "    prompt = \"Give me 5 fun and fascinating facts about tardigrades. Make them interesting and educational!\"\n",
    "    print(f\"No prompt entered. Using default: {prompt}\")\n",
    "\n",
    "# Asynchronous start of a Workflow\n",
    "handle = await client.start_workflow(\n",
    "    # TODO Pass in the Workflow you are running\n",
    "    GenerateReportInput(prompt=prompt),\n",
    "    id=f\"generate-research-report-workflow-{uuid.uuid4()}\", # user-defined Workflow identifier, which typically has some business meaning\n",
    "    task_queue=\"\", # TODO: Set the Task Queue to be the Task Queue that your Worker is polling\n",
    ")\n",
    "\n",
    "print(f\"Started workflow. Workflow ID: {handle.id}, RunID {handle.result_run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Run this cell to load and display the solution\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Markdown\n",
    "import os\n",
    "\n",
    "notebook_dir = Path(os.getcwd())\n",
    "solution_file = notebook_dir / \"Solutions_02_Adding_Durability_with_Temporal\" / \"client_solution.py\"\n",
    "\n",
    "code = solution_file.read_text()\n",
    "\n",
    "print(\"Solution loaded:\")\n",
    "display(Markdown(f\"```python\\n{code}\\n```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kvM082EAtXZv"
   },
   "source": [
    "### Getting the Result\n",
    "\n",
    "The example above uses async execution. You can `await` the handle to get the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VODi5uGZAj3j",
    "outputId": "50cd4396-b6e6-42ed-8e6a-5dbdefd517cb"
   },
   "outputs": [],
   "source": [
    "# Get the result\n",
    "result = await handle.result()\n",
    "print(f\"Result: {result}\")\n",
    "\n",
    "# To download the report: right click `research_pdf.pdf` in your file explore, then click `Download`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c4gwjNk6wx-L"
   },
   "source": [
    "### Temporal Web UI\n",
    "\n",
    "- Temporal provides a robust [Web UI](https://docs.temporal.io/web-ui) for managing Workflow Executions\n",
    "- Can gain insights like responses from Activities, execution time, and failures\n",
    "- Great for debugging and understanding what's happening during your Workflow Executions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vsOEZDrgGefo"
   },
   "source": [
    "### Exploring the Web UI\n",
    "\n",
    "Can you locate the following items on the Web UI?\n",
    "\n",
    "- The name of the Task Queue\n",
    "- The name of the two Activities called\n",
    "- The inputs and outputs of the called Activities\n",
    "- Input and output of the Workflow Execution\n",
    "\n",
    "_To See Your Web UI_: In your `Ports` tab on the bottom of this screen, find `8233` and click on the Globe icon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo (Expand for instructor notes or to run on your own)\n",
    "<!--\n",
    "Normal Execution Demo:\n",
    "1. To demonstrate the power of durable execution, we'll first show the power of running the app with no durable execution. This is the code that we showed in the first notebook.\n",
    "2. Clone this repository: `https://github.com/temporalio/edu-ai-workshop-agentic-loop`. The instructions will also be in the README.\n",
    "2. From the `demos/module_one_01_foundations_aiic_loop/app.py` directory, run `app.py` with `python app.py`.\n",
    "3. When prompted, provide the prompt you want to prompt OpenAI in the command line.\n",
    "4. Before the process generates a PDF, kill the process.\n",
    "5. Rerun the application again with `python app.py` and show that the process restarted and you have to have your application start the research again. Emphasize that from a cost perspective, this could be very costly, because you could have to re-run through many tokens to get to where you left off.\n",
    "\n",
    "Durable Execution Demo:\n",
    "1. Now show the durable version by switching into the ``demos/module_one_02_adding_durability` directory.\n",
    "2. Run the Worker with `python worker.py`.\n",
    "3. Run the Workflow with `python workflow.py`.\n",
    "4. When prompted, provide the prompt you want to prompt OpenAI in the command line.\n",
    "5. Before the process generates a PDF, kill the Worker.\n",
    "6. Rerun the Worker and show that you continue right where you left off.\n",
    "7. Emphasize that you lost no progress or data. The Workflow will continue by generating the PDF (available in the same directory) and completing the process successfully.\n",
    "10. Show the Workflow Execution completion in the Web UI.\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Durable Execution?\n",
    "\n",
    "* [Durable execution](https://docs.temporal.io/evaluate/understanding-temporal) is crash-proof execution\n",
    "* Retries upon failure\n",
    "* Maintains application state, resuming after a crash at the point of failure\n",
    "* Can run across a multitude of processes, even on different machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal Provides Durable Execution\n",
    "\n",
    "* Handles state, retries, timeouts, state preservation right out the box\n",
    "* Open-source MIT licensed\n",
    "* Code base approach to Workflow design\n",
    "  - Instead of building custom orchestration systems, you write normal functions.\n",
    "  - Since it’s a general purpose programming language, there are no abstractions to get in your way. Since AI patterns will continue to evolve, general-purpose programming languages will be as well-suited to implement these new patterns.\n",
    "* Use your own tools, processes, and libraries\n",
    "* Support for 7 languages (Python, Go, C#, Java, TypeScript, Ruby, PHP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulating Failure and Recovery\n",
    "\n",
    "Let's practice experiencing failure and recovery firsthand. We'll add a new feature to our workflow: generating an executive summary before creating the PDF. \n",
    "\n",
    "This will demonstrate:\n",
    "* How Activities automatically retry on failure\n",
    "* How Temporal preserves state across Worker restarts\n",
    "* How you can fix bugs without losing progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Create a New Activity with an Intentional Error\n",
    "\n",
    "We'll create a `generate_summary` Activity that:\n",
    "1. Takes the research content and generates a concise summary\n",
    "2. Contains an intentional error to simulate a real-world failure\n",
    "3. Will automatically retry when it fails\n",
    "\n",
    "Run the code below to add this Activity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code to create the Activity with an intentional error\n",
    "from temporalio import activity\n",
    "from temporalio.exceptions import ApplicationError\n",
    "\n",
    "@activity.defn\n",
    "def generate_summary(input: LLMCallInput) -> ModelResponse:\n",
    "    \"\"\"Generate a concise summary of the research content\"\"\"\n",
    "    \n",
    "    # This simulates a temporary failure - maybe a database is down, \n",
    "    # or an API is temporarily unavailable\n",
    "    raise ApplicationError(\n",
    "        \"Simulated failure: Summary service temporarily unavailable\"\n",
    "    )\n",
    "    \n",
    "    # This code would run if we remove the error above\n",
    "    response = completion(\n",
    "        model=LLM_MODEL,\n",
    "        api_key=LLM_API_KEY,\n",
    "        messages=[{\"content\": input.prompt, \"role\": \"user\"}]\n",
    "    )\n",
    "    return response\n",
    "\n",
    "print(\"Activity created with intentional error!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Update the Workflow to Call the Summary Activity\n",
    "\n",
    "Now we'll modify our Workflow to:\n",
    "1. Generate research content (existing)\n",
    "2. **Generate a summary of that research (new!)**\n",
    "3. Create the PDF with the summary (existing)\n",
    "\n",
    "Run the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated Workflow with summary generation step\n",
    "from datetime import timedelta\n",
    "from temporalio import workflow\n",
    "\n",
    "@workflow.defn(sandboxed=False)\n",
    "class GenerateReportWorkflow:\n",
    "\n",
    "    @workflow.run\n",
    "    async def run(self, input: GenerateReportInput) -> GenerateReportOutput:\n",
    "\n",
    "        # Step 1: Generate research content\n",
    "        llm_call_input = LLMCallInput(prompt=input.prompt)\n",
    "\n",
    "        research_facts = await workflow.execute_activity(\n",
    "            llm_call,\n",
    "            llm_call_input,\n",
    "            start_to_close_timeout=timedelta(seconds=30),\n",
    "        )\n",
    "\n",
    "        workflow.logger.info(\"Research complete!\")\n",
    "\n",
    "        # Step 2: Generate a summary (NEW - this will fail initially!)\n",
    "        summary_prompt = f\"Provide a 2-3 sentence executive summary of this research: {research_facts['choices'][0]['message']['content']}\"\n",
    "        summary_input = LLMCallInput(prompt=summary_prompt)\n",
    "\n",
    "        summary_result = await workflow.execute_activity(\n",
    "            generate_summary,\n",
    "            summary_input,\n",
    "            start_to_close_timeout=timedelta(seconds=30),\n",
    "        )\n",
    "\n",
    "        workflow.logger.info(\"Summary generated!\")\n",
    "        \n",
    "        # Step 3: Create PDF with summary prepended\n",
    "        full_content = f\"EXECUTIVE SUMMARY:\\n{summary_result['choices'][0]['message']['content']}\\n\\n{research_facts['choices'][0]['message']['content']}\"\n",
    "        pdf_generation_input = PDFGenerationInput(content=full_content)\n",
    "\n",
    "        pdf_filename = await workflow.execute_activity(\n",
    "            create_pdf_activity,\n",
    "            pdf_generation_input,\n",
    "            start_to_close_timeout=timedelta(seconds=10),\n",
    "        )\n",
    "\n",
    "        return GenerateReportOutput(result=f\"Successfully created research report PDF with summary: {pdf_filename}\")\n",
    "\n",
    "print(\"Workflow updated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Register the New Activity with the Worker\n",
    "\n",
    "We need to tell the Worker about our new `generate_summary` Activity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated Worker with the new Activity registered\n",
    "import concurrent.futures\n",
    "from temporalio.client import Client\n",
    "from temporalio.worker import Worker\n",
    "\n",
    "async def run_worker() -> None:\n",
    "    client = await Client.connect(\"localhost:7233\", namespace=\"default\")\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=100) as activity_executor:\n",
    "        worker = Worker(\n",
    "            client,\n",
    "            task_queue=\"research\",\n",
    "            workflows=[GenerateReportWorkflow],\n",
    "            activities=[llm_call, create_pdf_activity, generate_summary],  # Added generate_summary\n",
    "            activity_executor=activity_executor\n",
    "        )\n",
    "\n",
    "        print(f\"Starting the worker with summary Activity registered....\")\n",
    "        await worker.run()\n",
    "\n",
    "print(\"Worker function updated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kill the old worker and start the new one\n",
    "import asyncio\n",
    "\n",
    "x = worker.cancel()\n",
    "\n",
    "worker = asyncio.create_task(run_worker())\n",
    "print(\"New worker started!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Start a New Workflow Execution\n",
    "\n",
    "Let's start a new Workflow that will call our failing Activity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a new Workflow execution\n",
    "from temporalio.client import Client\n",
    "import uuid\n",
    "\n",
    "client = await Client.connect(\"localhost:7233\", namespace=\"default\")\n",
    "\n",
    "prompt = \"Give me 3 interesting facts about dolphins\"\n",
    "print(f\"Starting workflow with prompt: {prompt}\")\n",
    "\n",
    "handle = await client.start_workflow(\n",
    "    GenerateReportWorkflow,\n",
    "    GenerateReportInput(prompt=prompt),\n",
    "    id=f\"generate-report-with-summary-{uuid.uuid4()}\",\n",
    "    task_queue=\"research\",\n",
    ")\n",
    "\n",
    "print(f\"Started workflow. Workflow ID: {handle.id}\")\n",
    "print(f\"The workflow is now running and will retry the failing Activity automatically!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Observe Automatic Retries in the Web UI\n",
    "\n",
    "**Go to your Temporal Web UI now!**\n",
    "\n",
    "You should see:\n",
    "1. Your Workflow is **Running** (not Failed!)\n",
    "2. The `llm_call` Activity completed successfully ✓\n",
    "3. The `generate_summary` Activity shows a **Pending Activity** with retry attempts\n",
    "\n",
    "**Click on the Pending Activity to see:**\n",
    "- The error message. What does it say?\n",
    "- What is the current retry attempt number?\n",
    "- What is the countdown until the next retry?\n",
    "\n",
    "**Key insight:** Notice that the expensive `llm_call` Activity isn't being re-executed! Temporal saved its result and won't waste money calling the LLM again. Only the failing Activity retries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Fix the Error\n",
    "\n",
    "Now let's \"fix\" our simulated failure by removing the error. In a real scenario, this could be:\n",
    "- A database coming back online\n",
    "- An API endpoint being fixed\n",
    "- A network issue being resolved\n",
    "\n",
    "Fix the code by removing or commenting out the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Fix the code by removing or commenting out the error.\n",
    "# Step 2: Run the code block\n",
    "from temporalio import activity\n",
    "from litellm import completion\n",
    "\n",
    "@activity.defn\n",
    "def generate_summary(input: LLMCallInput) -> ModelResponse:\n",
    "    \"\"\"Generate a concise summary of the research content\"\"\"\n",
    "    \n",
    "    # This simulates a temporary failure - maybe a database is down, \n",
    "    # or an API is temporarily unavailable\n",
    "    raise ApplicationError(\n",
    "        \"Simulated failure: Summary service temporarily unavailable\"\n",
    "    )\n",
    "\n",
    "    # Error is now removed - the Activity will work!\n",
    "    response = completion(\n",
    "        model=LLM_MODEL,\n",
    "        api_key=LLM_API_KEY,\n",
    "        messages=[{\"content\": input.prompt, \"role\": \"user\"}]\n",
    "    )\n",
    "    return response\n",
    "\n",
    "print(\"Activity fixed! Error removed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Restart the Worker with Fixed Code\n",
    "\n",
    "Now restart the Worker so it picks up the fixed Activity code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kill the old worker and start the new one\n",
    "import asyncio\n",
    "\n",
    "x = worker.cancel()\n",
    "worker = asyncio.create_task(run_worker())\n",
    "print(\"New worker started!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Observe Successful Completion\n",
    "\n",
    "**Refresh your Web UI and observe:**\n",
    "\n",
    "1. The `generate_summary` Activity now completes successfully!\n",
    "2. The `create_pdf_activity` executes and creates the PDF\n",
    "3. The entire Workflow shows **Completed** status\n",
    "\n",
    "**What just happened?**\n",
    "- Your Workflow **preserved all state** through the failure\n",
    "- The expensive `llm_call` was **never re-executed** (saving you money!)\n",
    "- When you fixed the bug, Temporal **automatically continued** from where it left off\n",
    "- No manual intervention needed - just fix the code and restart the Worker\n",
    "\n",
    "**This is the power of durable execution!** In production, this means:\n",
    "- API outages don't lose your progress\n",
    "- You can deploy bug fixes without restarting workflows\n",
    "- Your users never lose work\n",
    "- You never pay twice for the same LLM call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Durable execution - State Preservation\n",
    "\n",
    "Temporal relies on a [Replay mechanism](https://docs.temporal.io/encyclopedia/event-history/event-history-python) to recover from failure.\n",
    "As your program progresses, Temporal saves the input and output from function calls to the history.\n",
    "This allows a failed program to restart right where it left off.\n",
    "This can also save us a lot of money since we aren't re-burning through tokens!\n",
    "\n",
    "For example:\n",
    "\n",
    "User request: \"Research sustainable energy trends\"\n",
    "- ✓ Step 1: LLM research call → Output saved to history\n",
    "- ✓ Step 2: Generate summary → Output saved to history  \n",
    "- ✗ Step 3: Create PDF → CRASH!\n",
    "\n",
    "On restart:\n",
    "- Temporal replays Steps 1 & 2 from history (no actual execution)\n",
    "- Continues from Step 3 with the same inputs\n",
    "\n",
    "_Read more about how Replay works in [this chapter](https://temporal.talentlms.com/unit/view/id:2847) of our free Temporal 102 course or read [this page](https://docs.temporal.io/encyclopedia/event-history/event-history-python#How-History-Replay-Provides-Durable-Execution) in our docs._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kill any worker to prepare for the exercise.\n",
    "x = worker.cancel()\n",
    "\n",
    "if x:\n",
    "  print(\"Worker killed\")\n",
    "else:\n",
    "  print(\"Worker was not running. Nothing to kill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pbw85OliybvN"
   },
   "source": [
    "--\n",
    "\n",
    "## Exercise 2 - Adding Durability\n",
    "\n",
    "* In these exercises you will:\n",
    "  * Transform your LLM calls and your execution of tools to Activities\n",
    "  * Use a Temporal Workflow to orchestrate your Activities\n",
    "  * Observe how Temporal handles your errors\n",
    "  * Debug your error and observe your Workflow Execution successfully complete\n",
    "* Go to the **Exercise** Directory and open the **02_Adding_Durability_with_Temporal** Directory\n",
    "* Open _Practice_ and follow the instructions\n",
    "* If you get stuck, raise your hand and someone will come by and help. You can also check the `Solution` directory for the answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's Next?\n",
    "\n",
    "This chapter introduced you to the **concept** of Durable Execution with Temporal. Further your learning with these resources:\n",
    "\n",
    "### Resources\n",
    "\n",
    "- Our free [Temporal 102 Course](https://learn.temporal.io/courses/temporal_102/python/) which covers these concepts (Workflows, Activities, Replay, and more) in more detail\n",
    "- A Temporal [tutorial in the Python SDK](https://learn.temporal.io/getting_started/python/hello_world_in_python/) that showcases how to get started with Temporal\n",
    "- Our [docs page](https://docs.temporal.io/encyclopedia/event-history/event-history-python#How-History-Replay-Provides-Durable-Execution) describing how Temporal uses Replay to provide durable execution in more detail"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (edu-ai-workshop-mcp)",
   "language": "python",
   "name": "edu-ai-workshop-mcp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

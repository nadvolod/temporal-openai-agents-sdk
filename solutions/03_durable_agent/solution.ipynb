{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29834b7d",
   "metadata": {},
   "source": [
    "# Exercise 3: Durable Agent â€” Solution\n",
    "\n",
    "Complete implementation combining OpenAI agents with Temporal for durability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa69615",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Ensure the Temporal dev server is running and `.env` contains your OpenAI credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f6609a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --quiet temporalio openai rich\n",
    "\n",
    "import os\n",
    "import asyncio\n",
    "import uuid\n",
    "from datetime import timedelta\n",
    "from openai import OpenAI\n",
    "from rich.console import Console\n",
    "from temporalio import activity, workflow\n",
    "from temporalio.client import Client\n",
    "from temporalio.worker import Worker\n",
    "from temporalio.common import RetryPolicy\n",
    "\n",
    "console = Console()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de44d61e",
   "metadata": {},
   "source": [
    "## Run the Solution\n",
    "\n",
    "Execute the workflow and observe durable behavior with retries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39181faf",
   "metadata": {
    "vscode": {
     "languageId": "bash"
    }
   },
   "outputs": [],
   "source": [
    "# Run the durable agent solution\n",
    "async def run_solution() -> None:\n",
    "    console.print(\"\\n[bold cyan]ðŸš€ Exercise 3: Durable Agent â€” Solution[/bold cyan]\\n\")\n",
    "\n",
    "    trace_id = str(uuid.uuid4())\n",
    "    console.print(f\"[yellow]Trace ID:[/yellow] {trace_id}\\n\")\n",
    "\n",
    "    client = await Client.connect(\"localhost:7233\")\n",
    "    task_queue = \"durable-agent-queue\"\n",
    "\n",
    "    async with Worker(\n",
    "        client,\n",
    "        task_queue=task_queue,\n",
    "        workflows=[DurableAgentWorkflow],\n",
    "        activities=[call_agent_with_tools],\n",
    "    ):\n",
    "        query = \"What's the weather like in San Francisco?\"\n",
    "        workflow_id = f\"durable-agent-{trace_id}\"\n",
    "\n",
    "        console.print(f\"[yellow]Query:[/yellow] {query}\\n\")\n",
    "\n",
    "        result = await client.execute_workflow(\n",
    "            DurableAgentWorkflow.run,\n",
    "            args=[query, trace_id],\n",
    "            id=workflow_id,\n",
    "            task_queue=task_queue,\n",
    "        )\n",
    "\n",
    "    console.print(f\"\\n[bold green]ðŸ¤– Agent Response:[/bold green]\\n{result}\\n\")\n",
    "    console.print(\n",
    "        f\"[yellow]View in Temporal UI:[/yellow] \"\n",
    "        f\"http://localhost:8233/namespaces/default/workflows/{workflow_id}\"\n",
    "    )\n",
    "    console.print(f\"[yellow]Trace ID for correlation:[/yellow] {trace_id}\\n\")\n",
    "\n",
    "asyncio.run(run_solution())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663a2ebc",
   "metadata": {},
   "source": [
    "## Source Code\n",
    "\n",
    "Inspect the solution modules below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ab66e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(location: str) -> str:\n",
    "    weather_data = {\n",
    "        \"San Francisco\": \"sunny, 72Â°F\",\n",
    "        \"New York\": \"cloudy, 65Â°F\",\n",
    "        \"London\": \"rainy, 58Â°F\",\n",
    "        \"Tokyo\": \"clear, 70Â°F\",\n",
    "    }\n",
    "    weather = weather_data.get(location, \"partly cloudy, 68Â°F\")\n",
    "    return f\"The weather in {location} is {weather}\"\n",
    "\n",
    "\n",
    "@activity.defn\n",
    "async def call_agent_with_tools(query: str, trace_id: str) -> str:\n",
    "    activity.logger.info(\"ðŸ¤– Activity started\")\n",
    "    activity.logger.info(f\"   Query: {query}\")\n",
    "    activity.logger.info(f\"   Trace ID: {trace_id}\")\n",
    "\n",
    "    client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_weather\",\n",
    "                \"description\": \"Get the current weather for a location\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"location\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The city name\",\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"location\"],\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    messages = [{\"role\": \"user\", \"content\": query}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "    )\n",
    "\n",
    "    response_message = response.choices[0].message\n",
    "    tool_calls = response_message.tool_calls\n",
    "\n",
    "    if tool_calls:\n",
    "        activity.logger.info(f\"ðŸ”§ Tool calls detected: {len(tool_calls)}\")\n",
    "        messages.append(response_message)\n",
    "\n",
    "        for tool_call in tool_calls:\n",
    "            function_name = tool_call.function.name\n",
    "            function_args = eval(tool_call.function.arguments)\n",
    "            activity.logger.info(f\"   Calling: {function_name}({function_args})\")\n",
    "\n",
    "            if function_name == \"get_weather\":\n",
    "                function_response = get_weather(**function_args)\n",
    "                messages.append(\n",
    "                    {\n",
    "                        \"tool_call_id\": tool_call.id,\n",
    "                        \"role\": \"tool\",\n",
    "                        \"name\": function_name,\n",
    "                        \"content\": function_response,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "        final_response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "        )\n",
    "        final_message = final_response.choices[0].message.content\n",
    "    else:\n",
    "        final_message = response_message.content\n",
    "\n",
    "    activity.logger.info(\"âœ… Activity completed\")\n",
    "    return final_message\n",
    "\n",
    "\n",
    "@workflow.defn\n",
    "class DurableAgentWorkflow:\n",
    "    @workflow.run\n",
    "    async def run(self, query: str, trace_id: str) -> str:\n",
    "        workflow.logger.info(\"ðŸš€ Durable agent workflow started\")\n",
    "        workflow.logger.info(f\"   Query: {query}\")\n",
    "        workflow.logger.info(f\"   Trace ID: {trace_id}\")\n",
    "\n",
    "        result = await workflow.execute_activity(\n",
    "            call_agent_with_tools,\n",
    "            args=[query, trace_id],\n",
    "            start_to_close_timeout=timedelta(seconds=30),\n",
    "            retry_policy=RetryPolicy(\n",
    "                initial_interval=timedelta(seconds=1),\n",
    "                maximum_interval=timedelta(seconds=10),\n",
    "                maximum_attempts=3,\n",
    "                backoff_coefficient=2.0,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        workflow.logger.info(\"âœ… Workflow completed successfully\")\n",
    "        return result\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

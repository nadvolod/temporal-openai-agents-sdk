{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29834b7d",
   "metadata": {},
   "source": [
    "# Exercise 3: Durable Agent â€” Solution\n",
    "\n",
    "Complete implementation combining OpenAI agents with Temporal for durability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa69615",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Ensure the Temporal dev server is running and `.env` contains your OpenAI credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f6609a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --quiet temporalio openai rich\n",
    "\n",
    "import json\n",
    "import os\n",
    "import asyncio\n",
    "import uuid\n",
    "from datetime import timedelta\n",
    "from openai import OpenAI\n",
    "from rich.console import Console\n",
    "from temporalio import activity, workflow\n",
    "from temporalio.client import Client\n",
    "from temporalio.worker import Worker, UnsandboxedWorkflowRunner\n",
    "from temporalio.common import RetryPolicy\n",
    "\n",
    "console = Console()\n",
    "\n",
    "\n",
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"Return mock weather information for instructional tool calls.\"\"\"\n",
    "    weather_data = {\n",
    "        \"San Francisco\": \"sunny, 72Â°F\",\n",
    "        \"New York\": \"cloudy, 65Â°F\",\n",
    "        \"London\": \"rainy, 58Â°F\",\n",
    "        \"Tokyo\": \"clear, 70Â°F\",\n",
    "    }\n",
    "    weather = weather_data.get(location, \"partly cloudy, 68Â°F\")\n",
    "    return f\"The weather in {location} is {weather}\"\n",
    "\n",
    "\n",
    "def _safe_parse_arguments(arg_string: str) -> dict:\n",
    "    try:\n",
    "        return json.loads(arg_string)\n",
    "    except json.JSONDecodeError:\n",
    "        activity.logger.warning(\"Failed to parse tool arguments: %s\", arg_string)\n",
    "        return {}\n",
    "\n",
    "\n",
    "@activity.defn\n",
    "async def call_agent_with_tools(query: str, trace_id: str) -> str:\n",
    "    \"\"\"Invoke the OpenAI agent with tool calling wrapped as a Temporal activity.\"\"\"\n",
    "    activity.logger.info(\"ðŸ¤– Activity started\")\n",
    "    activity.logger.info(\"   Query: %s\", query)\n",
    "    activity.logger.info(\"   Trace ID: %s\", trace_id)\n",
    "\n",
    "    client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_weather\",\n",
    "                \"description\": \"Get the current weather for a location\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"location\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"City name\",\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"location\"],\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful travel assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": query},\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "    )\n",
    "\n",
    "    response_message = response.choices[0].message\n",
    "    tool_calls = response_message.tool_calls\n",
    "\n",
    "    if tool_calls:\n",
    "        activity.logger.info(\"ðŸ”§ Tool calls detected: %d\", len(tool_calls))\n",
    "        messages.append(response_message)\n",
    "        for tool_call in tool_calls:\n",
    "            payload = _safe_parse_arguments(tool_call.function.arguments)\n",
    "            if tool_call.function.name == \"get_weather\" and payload.get(\"location\"):\n",
    "                tool_result = get_weather(**payload)\n",
    "                activity.logger.info(\"   Calling: %s(%s)\", tool_call.function.name, payload)\n",
    "                messages.append(\n",
    "                    {\n",
    "                        \"tool_call_id\": tool_call.id,\n",
    "                        \"role\": \"tool\",\n",
    "                        \"name\": tool_call.function.name,\n",
    "                        \"content\": tool_result,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "        follow_up = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "        )\n",
    "        final_message = follow_up.choices[0].message.content\n",
    "    else:\n",
    "        final_message = response_message.content\n",
    "\n",
    "    activity.logger.info(\"âœ… Activity completed\")\n",
    "    return final_message\n",
    "\n",
    "\n",
    "@workflow.defn\n",
    "class DurableAgentWorkflow:\n",
    "    \"\"\"Workflow coordinating the durable agent interaction.\"\"\"\n",
    "\n",
    "    @workflow.run\n",
    "    async def run(self, query: str, trace_id: str) -> str:\n",
    "        workflow.logger.info(\"ðŸš€ Durable agent workflow started\")\n",
    "        workflow.logger.info(\"   Query: %s\", query)\n",
    "        workflow.logger.info(\"   Trace ID: %s\", trace_id)\n",
    "\n",
    "        result = await workflow.execute_activity(\n",
    "            call_agent_with_tools,\n",
    "            args=[query, trace_id],\n",
    "            start_to_close_timeout=timedelta(seconds=30),\n",
    "            retry_policy=RetryPolicy(\n",
    "                initial_interval=timedelta(seconds=1),\n",
    "                backoff_coefficient=2.0,\n",
    "                maximum_interval=timedelta(seconds=10),\n",
    "                maximum_attempts=3,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        workflow.logger.info(\"âœ… Workflow completed successfully\")\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de44d61e",
   "metadata": {},
   "source": [
    "## Run the Solution\n",
    "\n",
    "Execute the workflow and observe durable behavior with retries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39181faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the durable agent solution\n",
    "async def run_solution() -> None:\n",
    "    console.print(\"\\n[bold cyan]ðŸš€ Exercise 3: Durable Agent â€” Solution[/bold cyan]\\n\")\n",
    "\n",
    "    trace_id = str(uuid.uuid4())\n",
    "    console.print(f\"[orange]Trace ID:[/orange] {trace_id}\\n\")\n",
    "\n",
    "    client = await Client.connect(\"localhost:7233\")\n",
    "    task_queue = \"durable-agent-queue\"\n",
    "\n",
    "    async with Worker(\n",
    "        client,\n",
    "        task_queue=task_queue,\n",
    "        workflows=[DurableAgentWorkflow],\n",
    "        activities=[call_agent_with_tools],\n",
    "        workflow_runner=UnsandboxedWorkflowRunner(),\n",
    "        debug_mode=True,\n",
    "    ):\n",
    "        query = \"What's the weather like in San Francisco?\"\n",
    "        workflow_id = f\"durable-agent-{trace_id}\"\n",
    "\n",
    "        console.print(f\"[orange]Query:[/orange] {query}\\n\")\n",
    "\n",
    "        result = await client.execute_workflow(\n",
    "            DurableAgentWorkflow.run,\n",
    "            args=[query, trace_id],\n",
    "            id=workflow_id,\n",
    "            task_queue=task_queue,\n",
    "        )\n",
    "\n",
    "    console.print(f\"\\n[bold green]ðŸ¤– Agent Response:[/bold green]\\n{result}\\n\")\n",
    "    console.print(\n",
    "        f\"[orange]View in Temporal UI:[/orange] \"\n",
    "        f\"http://localhost:8233/namespaces/default/workflows/{workflow_id}\"\n",
    "    )\n",
    "    console.print(f\"[orange]Trace ID for correlation:[/orange] {trace_id}\\n\")\n",
    "\n",
    "try:\n",
    "    loop = asyncio.get_running_loop()\n",
    "except RuntimeError:\n",
    "    asyncio.run(run_solution())\n",
    "else:\n",
    "    import nest_asyncio\n",
    "    nest_asyncio.apply()\n",
    "    task = loop.create_task(run_solution())\n",
    "    await task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663a2ebc",
   "metadata": {},
   "source": [
    "## Source Code\n",
    "\n",
    "The workflow and activity implementations are defined above in the first code cell."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
